The papers chosen, as well as the database of each work, are listed below:


### Action recognition for educational proposals applying concepts of Social Assistive Robotics

[Paper 1](https://www.sciencedirect.com/science/article/pii/S1389041721000723?casa_token=2RqLnweh1UAAAAAA:IMZKdwOdD9z0VFTbHv17CramkJoTH2ratRo_ok-oMyXq_H1PtDe2BblpW7f7kBAHmyuoCOgSuA)

- The database can be found by going to: [NERo-Dataset1](https://github.com/kevinbdc/NERO_ActionDataset1)

Action recognition has been gaining interest in research due to its great number of applications. So, the main contribution of this manuscript is a human–robot interaction framework, relying on dimension reduction of the system’s inputs in order to require a smaller dataset for training of an Artificial Neural Network. Our motivation is the development of a Social Assistive Robotics application. In summary, we choose nine standard actions to guide a robot, and two neutral ones to represent stand-by or resting cases. The dataset is created by people with different body shape, for robustness purposes, using only 5 to 10 samples of each class per person. Offline and online tests validate the method’s accuracy and confusion matrices clarify the results. A TicTacToe game using a ground robot exemplify a real world application, where each action represents a desired spot in the game. The results confirm a high accuracy, above 96.7%, in all the tests. Based on this, we can conclude our preprocessing strategy and classifier are capable of identifying the action patterns, even for a tiny dataset; thus, it is recommended for educational proposals due to its simplicity.

### Gestures-teleoperation of a heterogeneous multi-robot system

[Paper 2](https://link.springer.com/article/10.1007/s00170-021-07659-2)

- The database can be found by going to: [NERo-Dataset2](https://github.com/kevinbdc/NERO_ActionDataset2)

This work presents a solution for the teleoperation of a heterogeneous team of mobile robots. Regarding the team of robots, two possibilities are considered which are UAV-UGV (Unmanned Aerial Vehicle-Unmanned Ground Vehicle) and UAV-UAV. To execute this task, high-level gesture patterns are made in a remote station, and we proposed an easy-to-train Artificial Neural Network (ANN) classifier to identify the skeletal data extracted by an RGB-D (Red, Green, Blue-Depth) camera. Our classifier uses custom data to build the gesture patterns, allowing the use of smooth and intuitive gestures for the teleoperation of mobile robots. To validate our proposal, experiments were run using two off-the-shelf Parrot AR.Drone 2 quadrotors and the differential drive platform Pioneer 3-DX. The results of such experiments allow concluding that the proposed teleoperation system is able to accomplish inspection/surveillance tasks, and it can be easily modified to similar applications, as emergency response or load transportation.

### Learning from Experience for Rapid Generationof Local Car Maneuvers

[Paper 3](https://arxiv.org/abs/2012.03707)

- The database can be found by going to: [Pkicki's Dataset](https://github.com/pkicki/neural_path_planning)

Being able to rapidly respond to the changing scenes and traffic situations by generating feasible local paths is of pivotal importance for car autonomy. We propose to train a deep neural network (DNN) to plan feasible and nearly-optimal paths for kinematically constrained vehicles in small constant time. Our DNN model is trained using a novel weakly supervised approach and a gradient-based policy search. On real and simulated scenes and a large set of local planning problems, we demonstrate that our approach outperforms the existing planners with respect to the number of successfully completed tasks. While the path generation time is about 40 ms, the generated paths are smooth and comparable to those obtained from conventional path planners.
